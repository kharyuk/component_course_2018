{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Курс \"Компонентные модели\"\n",
    "\n",
    "## Автор: Харюк Павел, аспирант факультета ВМК МГУ имени М.В. Ломоносова\n",
    "### Составлено: 2017-2018 гг."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Занятие 6. Тензорные разложения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Базовые операции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисления\n",
    "\n",
    "Перемножение по $k$-й моде (contraction):\n",
    "\n",
    "$$(X \\times_k Y)[i_1, \\ldots, i_{d_x}, j_1, \\ldots, j_{d_y}] = \\sum\\limits_{p=1}^{n_k} X[i_1, \\ldots, p, \\ldots i_{d_x}] \\cdot Y[j_1, \\ldots, p, \\ldots i_{d_y}]$$\n",
    "\n",
    "Скалярное произведение (inner product):\n",
    "$$\\langle X, Y \\rangle = X \\times_{k=1}^{d} Y$$\n",
    "\n",
    "### Изменение размерности\n",
    "\n",
    "Важная группа операций связана с изменениями размерности тензора. Моды можно объединять, уменьшая размерность. Объединение всех мод в одну происходит при *векторизации* тензора: ${vec}(X) \\in \\mathbb{R}^{\\prod\\limits_{k=1}^{d} n_k}$; для удобства можно рассматривать конечный результат как столбцовый или строчный вектор. В обоих случая требуется задать правило перевода элементов в новые позиции, чаще всего это т.н. \"столбцовый порядок\" (в программировании - Fortran order):\n",
    "$$\n",
    "f(i_1, \\ldots, i_d) = \\sum\\limits_{k=1}^{d} i_k \\prod\\limits_{0 \\leq l<k} n_l \n",
    "$$\n",
    "\n",
    "Здесь и далее мы используем столбцовый порядок. Чтобы понять происхождение такого названия, достаточно рассмотреть векторизацию матрицы (двумерного тензора): столбцовый порядок означает последовательное соединение столбцов. В **numpy** операцию изменения размерности можно реализовать с помощью **reshape**, векторизации - **flatten**. По умолчанию **numpy** использует *C order* (строчный порядок), для выбора столбцового достаточно указать в параметрах **order='F'**\n",
    "\n",
    "Другая полезная операция - построение *матрицы развёртки (unfolding)*. Укажем два способа.\n",
    "\n",
    "Развёртка по $k$-й моде:\n",
    "$$\n",
    "{unfold}_k(X) = X_{(k)} \\in \\mathbb{R}^{n_k \\times \\prod\\limits_{l \\neq k} n_l}\n",
    "$$\n",
    "\n",
    "Развёртка по первым $k$ индексам:\n",
    "$$\n",
    "{unfold}_{\\leq k} (X) = X^{\\leq k} \\in \\mathbb{R}^{\\prod\\limits_{p=1}^{k} n_p \\times \\prod\\limits_{q=k+1}^{d} n_q}\n",
    "$$\n",
    "\n",
    "\n",
    "Результат операции в англоязычных работах также называют ***left interface matrix***. \n",
    "\n",
    "Если число отсчётов в $k$-й моде позволяет разложить $n_k$ на множители, то можно произвести операцию ***тензоризации (tensorization)***. Заметим, что это не единственный способ увеличить размерность данных. Другой возможный путь - применить некоторое преобразование. В одной из лекций мы рассмотрим частотно-временные разложения как способ извлечения дополнительной моды для сигналов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Другие операции\n",
    "\n",
    "Кронекерово произведение матриц (операнды - матрицы произвольных размеров):\n",
    "$$A \\otimes B = \\begin{bmatrix} a_{11} B & \\ldots & a_{1n} B \\\\ \\vdots & \\ddots & \\vdots \\\\ a_{m1} B & \\ldots & a_{mn} B\\\\ \\end{bmatrix}$$\n",
    "\n",
    "Столбцовое произведение Хатри-Рао (операнды - матрицы, имеющие одинаковое число столбцов):\n",
    "$$A \\odot B = \\begin{bmatrix} a_{1} \\otimes b_{1} & a_{2} \\otimes b_{2} & \\ldots & a_{n} \\otimes b_{n} \\end{bmatrix}$$\n",
    "\n",
    "Адамарово произведение матриц (поэлементное умножение, операнды - матрицы одинаковых размеров):\n",
    "$$A \\fbox{*} B = \\begin{bmatrix} a_{11} \\cdot b_{11} & \\ldots & a_{1n} \\cdot b_{1n} \\\\ \\vdots & \\ddots & \\vdots \\\\ a_{m1} \\cdot b_{m1} & \\ldots & a_{mn} \\cdot b_{mn} \\\\ \\end{bmatrix}$$\n",
    "\n",
    "Полезные соотношения:\n",
    "\n",
    "$${vec} (AXB^T) = (B \\otimes I) {vec} (AX) = (I \\otimes A) {vec} (XB^T) = (B \\otimes A) {vec} (X)$$\n",
    "$$\\frac{\\partial {vec}(AB^T)}{\\partial {vec} (A)} = (B \\otimes I), \\quad \\frac{\\partial {vec}(AB^T)}{\\partial {vec} (B)} = (I \\otimes A)$$\n",
    "$$(AB)\\otimes(CD) = (A \\otimes C) (B \\otimes D), \\quad \\text{если размеры матриц позволяют}$$\n",
    "$$(A \\otimes B)^T = (A^T) \\otimes (B^T)$$\n",
    "$$(B \\odot A)^T (B \\odot A) = (B^T B) \\fbox{*} (A^T A) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тензорные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ряд тензорных разложений можно изобразить графически в виде структуры, напоминающей граф, следующего вида:\n",
    "\n",
    "1) каждая вершина представляет собой тензор;\n",
    "\n",
    "2) каждая мода тензора обозначается отдельным ребром, исходящим из вершины;\n",
    "\n",
    "3) если две вершины соединяются общим ребром, то по соответсвующим модам производится умножение.\n",
    "\n",
    "Можно расширить используемые обозначения и для других операций, однако мы ограничимся только перемножением по $k$-й моде."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разложение Таккера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первое тензорное разложение, которое мы рассмотрим на этом занятии, - разложение Таккера:\n",
    "\n",
    "$$X(\\alpha_1, \\ldots, \\alpha_d) = G(\\gamma_1, \\ldots, \\gamma_d) \\times_{\\gamma_1} A_1(\\alpha_1, \\gamma_1) \\times_{\\gamma_2} A_2(\\alpha_2, \\gamma_2) \\times_{\\gamma_3} \\ldots \\times_{\\gamma_d} A_d(\\alpha_d, \\gamma_d)$$\n",
    "\n",
    "$$X[i_1, \\ldots, i_d] = \\sum\\limits_{p_1=1}^{r_1} \\ldots \\sum\\limits_{p_d=1}^{r_d} G[p_1, \\ldots, p_d] \\cdot A_1[i_1, p_1] \\cdot A_2[i_2, p_2] \\cdot \\ldots \\cdot  A_d[i_d, p_d]$$\n",
    "\n",
    "Число параметров: $O(dnr + r^d)$\n",
    "\n",
    "Векторизация разложения Таккера может быть записана в следующем виде:\n",
    "\n",
    "$${vec} \\big( G(\\gamma_1, \\ldots, \\gamma_d) \\times_{\\gamma_1} A_1(\\alpha_1, \\gamma_1) \\times_{\\gamma_2} A_2(\\alpha_2, \\gamma_2) \\times_{\\gamma_3} \\ldots \\times_{\\gamma_d} A_d(\\alpha_d, \\gamma_d) \\big) = \\big( A_d \\otimes A_{d-1} \\otimes \\ldots \\otimes A_1 \\big) {vec} \\big( G\\big)$$\n",
    "\n",
    "Матрица развёртки по $k$-му индексу:\n",
    "\n",
    "$${unfold}_k \\big( G(\\gamma_1, \\ldots, \\gamma_d) \\times_{\\gamma_1} A_1(\\alpha_1, \\gamma_1) \\times_{\\gamma_2} A_2(\\alpha_2, \\gamma_2) \\times_{\\gamma_3} \\ldots \\times_{\\gamma_d} A_d(\\alpha_d, \\gamma_d) \\big) = A_k G_{(k)} \\big( A_d \\otimes A_{d-1} \\otimes \\ldots A_{k+1} \\otimes A_{k-1} \\otimes \\ldots \\otimes A_1 \\big)$$\n",
    "$$G_{(k)} = {unfold}_k \\big( G \\big)$$\n",
    "\n",
    "С помощью разложения Таккера можно ввести многомерное обобщение сингулярного разложения (HOSVD). Для этого все \n",
    "\n",
    "Условия единственности - удивительно, что разложение Таккера с дополнительными условиями всё-таки может быть единственным. Авторы ([Guoxu et al](https://arxiv.org/abs/1404.4412)) приводят доказательство, что достаточно разреженное неотрицательное разложение обладает свойством единтсвенности.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Каноническое разложение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каноническое разложение можно рассматривать как частный случай разложения Таккера с диагональным ядром, имеющем одинаковые размеры по всем модам. Однако, разложение обладает отличительными свойствами: каноническое разложение Тензора единственно. Вместе с тем теория утверждает, что невозможно в общем случае построить наилучшее приближение точного ранга.\n",
    "\n",
    "Число параметров: $O(dnr)$\n",
    "\n",
    "Векторизация канонического разложения может быть записана в том же виде, что и для разложения Таккера, однако из-за особой структуры ядра разложения, матрица развёртки может быть записана более компактно:\n",
    "\n",
    "$${unfold}_k \\big( I(\\gamma, \\ldots, \\gamma) \\times_{\\gamma} C_1(\\alpha_1, \\gamma) \\times_{\\gamma} C_2(\\alpha_2, \\gamma) \\times_{\\gamma} \\ldots \\times_{\\gamma} C_d(\\alpha_d, \\gamma) \\big) = C_k \\big( C_d \\odot C_{d-1} \\odot \\ldots \\odot C_{k+1} \\odot C_{k-1} \\odot \\ldots C_1 \\big)^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разложение Tensor Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разложение тензорного поезда определяется следующим образом:\n",
    "\n",
    "$$A(\\alpha_1, \\ldots, \\alpha_d) = G_1(\\alpha_1, \\gamma_1) \\times_{\\gamma_1} G_2(\\gamma_1, \\alpha_2, \\gamma_2) \\times_{\\gamma_2} \\ldots \\times_{\\gamma_{d-1}} G_d(\\gamma_{d-1}, \\alpha_d) \\quad \\text{(тензорный вид)}$$\n",
    "\n",
    "$$A[i_1, \\ldots, i_d] = \\sum\\limits_{p_1=1}^{r_1} \\ldots \\sum\\limits_{p_{d-1}=1}^{r_{d-1}} G_1[i_1, p_1] \\cdot G_2[p_1, i_2, p_2] \\cdot \\ldots \\cdot G_d[p_{d-1}, i_d]  \\quad \\text{(поэлементный вид)}$$\n",
    "\n",
    "Также разложения известно под названием matrix product states (MPS).\n",
    "\n",
    "Число параметров: $O(dnr^2)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Иерархическое разложение Таккера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблемой обычного разложения таккера является экспоенциальная зависимость от ранга разложения, которая возникает из-за наличия ядра той же размерности, что и исходный тензор. Идея иерархического разложения Таккера - продолжить разложение для ядра, уходя на несколько уровней вглубь. При этом размерность уменьшается в результате попарного объединения мод. Рассмотрим векторизацию разложения:\n",
    "\n",
    "$${vec} \\big(T \\big) = \\big( A_d \\otimes A_{d-1} \\otimes \\ldots \\otimes A_1 \\big) {vec} \\big( G\\big)$$\n",
    "\n",
    "Ядро $G \\in \\mathbb{R}^{r_1 \\times \\ldots \\times r_d}$ приводится к виду $\\widehat{G} \\in \\mathbb{R}^{r_1\\cdot r_2 \\times r_3 \\cdot r_4 \\times \\ldots \\times s}$, где $s = \\begin{cases} r_{d-1} \\cdot r_d, & \\text{d - чётное}\\\\ r_d, & \\text{d - нечётное} \\end{cases}$. При этом не обязательно спаривать соседние индексы; для большей понятности мы рассмотрим случай чётного $d$ и спаривания соседних мод. Для $\\widehat{G}$ далее строится своё разложение Таккера. Векторизация при этом примет вид:\n",
    "\n",
    "$${vec} \\big(T \\big) = \\big( A_d \\otimes A_{d-1} \\otimes \\ldots \\otimes A_1 \\big) \\big( A_{d, d-1} \\otimes A_{d-2, d-3} \\otimes \\ldots \\otimes A_{2, 1} \\big) {vec} \\big( G_{level=2}\\big)$$\n",
    "\n",
    "Разложение продолжается до тех пор, пока не будут объединены все моды. \n",
    "\n",
    "Сложность: $O\\big(dnr + (d-2)r^3 + r^2\\big)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычисление разложений\n",
    "\n",
    "Для вычисления разложений необходимо сформулировать оптимизационную задачу. Часто встречается формулировка в виде задачи нелинейных наименьших квадратов, рассмотренной ранее в курсе. Для некоторых разложений существуют алгебраические методы вычисления.\n",
    "\n",
    "### Tucker\n",
    "\n",
    "Алгоритм HOSVD: последовательно рассматриваются развёртки по $k$-му индексу исходного тензора, из них оцениваются левые сингулярные матрицы, первые $r_k$ стоолбцов которых и формируют соответствующую фактор-матрицу $U_k$. Ядро оценивается последовательным умножением по $k$-му индексу исходного тензора на $U_k$, \n",
    "$$U_{r_k} \\Sigma_{r_k} V^T_{r_k} = \\text{unfold}_{k} (A), \\quad G = |[A; U_{r_1}^T, \\ldots, U_{r_d}^T]|, \\quad A \\approx |[G; U_{r_1}, \\ldots, U_{r_d}]|$$\n",
    "\n",
    "### TT\n",
    "\n",
    "Для вычисления разложения тензорного поезда существует алгоритм TT-SVD. Вычисления схожи с HOSVD:\n",
    "- на первой итерации берётся развёртка тензора $A$ по первому индексу и вычисляется её сингулярное разложение, в котором обнуляются все малые сингулярные числа (меньшие $\\delta = \\frac{\\varepsilon}{\\sqrt{d-1}} \\|A\\|_F$):\n",
    "$$A_{(1)} = B_1 = U_1 \\Sigma_1 V_1^T + E, \\, \\text{rank}(E) \\leq \\delta, \\quad r_1 = \\text{rank}_{\\delta} (C)$$\n",
    "Матрица $U_1$ сохраняется как первое ядро разложения, далее работа ведётся с $B_2 = \\Sigma_1 V_1^T$\n",
    "\n",
    "- на следующей итерации и на всех последующих, за исключением последней, берётся развёртка $B_2$ по первым двум индексам, и вновь вычиляется сингулярное разложение с обнулением по параметру $\\delta$. Первые две моды левой сингулярной матрицы разделяются, и получаем второе ядро разложения.\n",
    "\n",
    "- далее процесс повторяется до последней размерности, для которой в качестве последнего ядра выбирается произведение матрицы сингулярных чисел и правой сингулярной матрицы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Число компонент\n",
    "\n",
    "Отдельным вопросом является оценка числа компонент разложений. До сих пор мы рассматривали разложения, для которых ранги считаются фиксированными. Наиболее простой способ определения оптимального числа компонент - \n",
    "последовательный перебор с вычислением значений некоторого функционала качества, пока эти значения не станут приемлемыми. Однако такой подход требует пересчёта разложения, что часто довольно дорого.\n",
    "\n",
    "В случае TT разложения достаточно указать желаемую точность аппроксимации, и алгоритм TT-SVD построит разложение с заданной точностью. Однако если на ядра разложения накладываются дополнительные условия, то проблема выбора ранга появляется и здесь. \n",
    "\n",
    "### CPD: rank consistency\n",
    "\n",
    "Чтобы не перегружать изложение, рассмотрим трёхмерный случай: пусть имеется некоторое каноническое разложение тензора $T$:\n",
    "$$T = |[I; C_1, C_2, C_3]|$$\n",
    "\n",
    "Построим для него линейную регрессию вида (подробнее о линейной регрессии будет сказано на 8-м занятии):\n",
    "\n",
    "$$(C_3 \\otimes C_2 \\otimes C_1) \\text{vec}(G) = \\text{vec}(T)$$\n",
    "\n",
    "Выражение справа означает векторизацию разложения Таккера с ядром $G$ и фактор-матрицами из канонического разложения. Предположение следующее: если фактор-матрицы хорошо оценивают исходный тензор, то решение этой системы уравнений даст векторизацию тензора $G$, близкого к единичному диагональному $I$.\n",
    "\n",
    "Для анализа того, насколько подходит каноническая модель с фактор-матрицми $C_1, C_2, C_3$ для описания тензора $T$, решается указанная линейная регрессия, и рассматривается величина\n",
    "$$\\text{core consistency} = 1 - \\frac{\\|I - G\\|_F^2}{\\|I\\|_F^2}$$\n",
    "\n",
    "Обычно полагают, что диапазон значений 0.9--1.0 соответствует хорошей модели, 0.0--0.5 - плохой.\n",
    "\n",
    "### Tucker: разреженность ядра\n",
    "\n",
    "В работе [Multilinear tensor rank estimation via Sparse Tucker Decomposition](https://ieeexplore.ieee.org/document/7044685/) проблема выбора ранга для разложения Таккера решалась через введение условия разреженности ядра и ортогональности фактор-матриц:\n",
    "\n",
    "$$\\begin{array}{rl}\n",
    "\\min & \\|G\\|_1 \\\\\n",
    "\\text{s.t.} & \\|T - |[G; A_1, \\ldots, A_d]|\\|_F^2 \\leq \\varepsilon,\\\\\n",
    "& A_i^T A_i = I_{r_i}, \\quad i=\\overline{1, d}\n",
    "\\end{array}$$\n",
    "\n",
    "Для полученного разложения строились множества $H_k$ или $S_k$ по следующим правилам:\n",
    "\n",
    "$$H_k = \\{i\\,|\\quad G_{(k)}[i, j] = 0, \\quad \\forall j\\}$$\n",
    "$$S_k = \\Big\\{i\\,\\Big|\\quad 1 - \\frac{\\|G_{(k)}[i, :]\\|_1}{\\|G_{(k)}\\|_1} \\geq \\rho\\Big\\}, \\quad \\rho \\in [0, 1]$$\n",
    "\n",
    "Все столбцы фактор-матриц, индексы которых попали во множество $S_k$ (или $H_k$), удаляются.\n",
    "\n",
    "\n",
    "## PCA/SVD анализ матриц развёртки\n",
    "\n",
    "Такой анализ проводится для каждой модальности отдельно через матрицы развёртки. Рассматриваются соответсвующие ковариационные матрицы $R_k = \\frac{1}{n_k} T_{(k)} T_{(k)}^T$. Их представляют в виде\n",
    "$$R_k = V_{k; S} \\Lambda_{k; S} V_{k; S}^T + V_{k; N} \\Lambda_{k; N} V_{k; N}^T = \n",
    "\\begin{bmatrix}\n",
    "V_{k; S} & V_{k; S} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\Lambda_{k; S} & \\\\\n",
    "& \\Lambda_{k; N} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "V_{k; S} V_{k; S} \\\\\n",
    "\\end{bmatrix}^T\n",
    "$$\n",
    "\n",
    "Первая часть соответствует полезному сигналу, вторая - шуму. Чтобы определить, насколько малые сингулярные числа можно отбросить, можно использовать следующую эвристику:\n",
    "\n",
    "$$\\text{GAP}(p) = \\frac{\\text{var}\\Big(\\begin{bmatrix}\\hat{\\lambda}_{p+1} & \\ldots & \\hat{\\lambda}_{n_k-1} \\end{bmatrix}^T\\Big)}{\\text{var}\\Big(\\begin{bmatrix}\\hat{\\lambda}_{p} &  \\ldots & \\hat{\\lambda}_{n_k-1}\\end{bmatrix}^T\\Big)}, \\quad p=\\overline{1, n_k-2}, \\quad \\hat{\\lambda}_i = \\lambda_i - \\lambda_{i+1},$$\n",
    "\n",
    "и $r_k = \\arg \\min\\limits_{p=\\overline{1, n_k-2}} \\text{GAP}(p)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Напишите формулу перевода мульти-индекса $(i_1, \\ldots, i_d)$ при векторизации для строчного порядка (C order).\n",
    "\n",
    "2. Реализуйте каноническое разложение и разложение Таккера методом ALS. Сравните результаты работы алгоритма с ортогонализацией фактор-матриц на каждом шаге и без. Оценку качества работы проведите следующим образом: сэмплируйте параметры разложения (фактор-матрицы, ядро) при заданных гиперпараметрах, восстановите из них тензор в полном формате, далее необходимо построить приближение реализованным методом при тех же параметрах. В качестве критерия качества используйте относительную невязку.\n",
    "\n",
    "3. Добавьте в алгоритм, полученный в задании два, условие неотрицательности фактор-матриц. Используйте проекционный метод. Протестируйте по схеме, аналогичной той, что рассмотрена во втором задании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительные материалы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www2.mpi-magdeburg.mpg.de/mpcsc/events/trogir/slides/tensorlectures.pdf\n",
    "\n",
    "https://www.mis.mpg.de/preprints/2009/preprint2009_27.pdf\n",
    "\n",
    "http://www.sam.math.ethz.ch/sam_reports/reports_final/reports2012/2012-02_fp.pdf\n",
    "\n",
    "Cichocki et al. Non-negative matrix and tensor factorizations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
